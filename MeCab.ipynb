{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◯　PythonでMeCabを利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'日本シリーズ で ソフトバンク が 勝利 \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MeCab\n",
    "m = MeCab.Tagger('-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "m.parse(\"日本シリーズでソフトバンクが勝利\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['日本シリーズ', 'で', 'ソフトバンク', 'が', '勝利', '\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 半角スペース区切りで単語を分解する\n",
    "m.parse(\"日本シリーズでソフトバンクが勝利\").split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['日本シリーズ', 'ソフトバンク', '勝利']\n"
     ]
    }
   ],
   "source": [
    "# 名詞だけをカウントする\n",
    "nodes = m.parseToNode(\"日本シリーズでソフトバンクが勝利\")\n",
    "surfaces = []\n",
    "while nodes:\n",
    "    if nodes.feature[:2] == '名詞':\n",
    "        surfaces.append(nodes.surface)\n",
    "    nodes = nodes.next\n",
    "print(surfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 1]]), ['ソフトバンク', '勝利', '新機種', '日本シリーズ', '発売', '錦織圭'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文書をベクトルにする\n",
    "# Bag of Wordsの形式を示す　→　該当する文書に単語が含まれているかを指す\n",
    "# 各次元がどの単語に対応しているかはcount_vectorizer.get_feature_names()で確認できる\n",
    "import MeCab\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "doc_1 = m.parse(\"日本シリーズでソフトバンクが勝利\")\n",
    "doc_2 = m.parse(\"ソフトバンクが新機種を発売\")\n",
    "doc_3 = m.parse(\"錦織圭が勝利\")\n",
    "vectors = count_vectorizer.fit_transform([doc_1, doc_2, doc_3])\n",
    "vectors.toarray(), count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◯　文書分類を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのニュース記事がどのメディアの記事なのかを予測する準備\n",
    "import os\n",
    "import MeCab\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "MEDIA_LIST = [\n",
    "    'dokujo-tsushin',\n",
    "    'it-life-hack',\n",
    "    'kaden-channel',\n",
    "    'livedoor-homme',\n",
    "    'movie-enter',\n",
    "    'peachy',\n",
    "    'smax',\n",
    "    'sports-watch',\n",
    "    'topic-news',\n",
    "]\n",
    "\n",
    "def get_title_from_txt(txt):\n",
    "    title = ' '.join(txt.split('\\n')[2:])\n",
    "    return title\n",
    "\n",
    "def load_livedoornews_corpus():\n",
    "    corpus = []\n",
    "    for media_idx, media in enumerate(MEDIA_LIST):\n",
    "        for filename in os.listdir('./livedoor_newscorpus/{}/'.format(media)):\n",
    "            txt = open('./livedoor_newscorpus/{}/{}'.format(media, filename), encoding=\"utf8\", errors='ignore').read()\n",
    "            title = get_title_from_txt(txt)\n",
    "            corpus.append((media_idx, title))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_livedoornews_corpus()\n",
    "media_labels = []\n",
    "docs = []\n",
    "m = MeCab.Tagger('-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "for media_idx, title in corpus:\n",
    "    \n",
    "    media_labels.append(media_idx)\n",
    "    words = m.parse(title)\n",
    "    docs.append(words)\n",
    "    \n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectors = count_vectorizer.fit_transform(docs)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94241192, 0.95389831, 0.95457627, 0.95322034, 0.93830508])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出現頻度を用いた場合\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=300)\n",
    "cross_val_score(model, count_vectors, media_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91802168, 0.91932203, 0.92745763, 0.92745763, 0.91389831])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDFを用いた場合\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=300)\n",
    "cross_val_score(model, tfidf_vectors, media_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
